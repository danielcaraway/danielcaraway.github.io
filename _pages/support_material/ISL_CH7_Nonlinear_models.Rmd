---
title: "ISL_CH7"
output: html_document
---

```{r}
rm(Wage)
require(ISLR)
attach(Wage)
```

## Polynomials

1. FIRST focus on a single predictor, AGE


NOTES FROM VIDEO:
We will fit a fourth degree polynomial to The Age/Wage regression 
The function `poly` does the matrix-making for us!




```{r}
fit=lm(wage~poly(age,4),data=Wage)
summary(fit)
```

```{r fig.width=3, fig.height=3}
# get limits from age range
agelims=range(age)
# creates a sequence of nums from both ends of agelist
age.grid=seq(from=agelims[1],to=agelims[2])
# makes the predictions, also includes standard error
# returns two lists, one list of predictions, one with the standard errors
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
# use cbind to take two columns (lists) and turn into matrix
# And use +2 and -2 to create our Standard Error Bands
# preds$fit = predictions | preds$se = standard error
se.bands=cbind(preds$fit+2*preds$se, preds$fit-2*preds$se)
# first plot the data
plot(age, wage, col="darkgrey")
# then plot our error bands
lines(age.grid, preds$fit, lwd=2, col="blue")
matlines(age.grid,se.bands,col="blue",lty=2)
```

There are other ways we can do this in R

```{r}
# wrap ^2 in "identity function" so the carat won't be 
# interpreted as part of the forumla -- I(age^2) == age squared
# I(age^3) == age cubed etc.
fit_v2=lm(wage~age+I(age^2)+I(age^3)+I(age^4),data=Wage)
summary(fit_v2)
```

## ON TO ANOVA

```{r}
fita=lm(wage~education, data=Wage)
fitb=lm(wage~education+age,data=Wage)
fitc=lm(wage~education+poly(age,2),data=Wage)
fitd=lm(wage~education+poly(age,3),data=Wage)
anova(fita, fitb, fitc, fitd)
```

NOTES FROM THE VIDEO: 

We use the ANOVA to tell us which variables we need.
As we can see by the `***` we clearly need Age, and Age ^2. 
Age ^3 is only statistically significant at the 5% level (see `Signif.codes: *`)

## POLYNOMIAL LOGISTIC REGRESSION

We are going to separate out the "big wage earners" into a binary variable
And then fit this to a logistic regression (which only works with binary response variables)

```{r}
# Run the model
fit=glm(I(wage>250) ~ poly(age,3), data=Wage, family=binomial)
# Get the summary
summary(fit)
# Get the prediction
preds=predict(fit,list(age=age.grid),se=T)
# Create Standard Error Bands
se.bands=preds$fit + cbind(fit=0,lower=-2*preds$se,upper=2*preds$se)
se.bands[1:5,]
```

```{r}
prob.bands=exp(se.bands)/(1+exp(se.bands))
matplot(age.grid,prob.bands,col="blue",lwd=c(2,1,1),lty=c(1,2,2),type="l",ylim=c(0,.1))
# we use the jitter function to show just how much data happened at each age
points(jitter(age), I(wage>250)/10,pch="l",cex=.5)
```

### PURPOSE: 
* Confidence band is first computed on the LOGIT scale (where we are comparing the binary high/low earners) 
* And then APPLIED to our probability scale 

UPNEXT: Splines


# SPLINES

Splines are more flexible than polynomials 
(but the idea is similar)

### Exploring cubic splines

A spline is a cubic polynomial
Splines help us fit more flexible functions
The knots break down the data
Splines are more "local" than polynomials

Here is a "fixed knot regression spline"

```{r}
require(splines)
fit=lm(wage~bs(age, knots=c(25,40,60)), data=Wage)
plot(age,wage,col="darkgrey")
lines(age.grid,predict(fit,list(age=age.grid)),col="darkgreen",lwd=2)
abline(v=c(25,40,60),lty=2,col="darkgreen")
```
## SMOOTHING SPLINE

Smoothing spline does not require knot selection 
it DOES have a smoothing parameter
and it can be specified via the "degress of freedom" or `df`
```{r}
fit=lm(wage~bs(age, knots=c(25,40,60)), data=Wage)
plot(age,wage,col="darkgrey")
lines(age.grid,predict(fit,list(age=age.grid)),col="darkgreen",lwd=2)
abline(v=c(25,40,60),lty=2,col="darkgreen")
# ----------
fit=smooth.spline(age,wage,df=16)
lines(fit,col="red",lwd=2)
```

Alternately we can use LOO cross-validation 
Which selects our smoothing parameter for us automatically

```{r}
fit=lm(wage~bs(age, knots=c(25,40,60)), data=Wage)
plot(age,wage,col="darkgrey")
lines(age.grid,predict(fit,list(age=age.grid)),col="darkgreen",lwd=2)
abline(v=c(25,40,60),lty=2,col="darkgreen")
# ----------
fit=smooth.spline(age,wage,df=16)
lines(fit,col="red",lwd=2)
# ----------
fit=smooth.spline(age,wage,cv=TRUE)
lines(fit,col="purple",lwd=2)
fit
```
## What about MULTIPLE non-linear terms?

So far, we've only looked at single non-linear terms.
Thankfully, the `gam` package makes working with multiple non-linear terms easier 

```{r}
require(gam)
# We tell "gam" the the response is WAGE
# We want a smooth term in age, with four degrees of freedom
# We want a smooth term in year, also with four degrees of freedom
# As edu is a factor variable, it will make dummy variables for us
# NOTE: S is a special function in `gam` that denotes smoothing
gam1=gam(wage~s(age,df=4)+s(year,df=4)+education,data=Wage)
par(mfrow=c(1,3))
# Excellent way to fit and plot non-linear functions across several variables
plot(gam1,se=T)
gam2=gam(I(wage>250)~s(age,df=4)+s(year,df=4)+education,data=Wage,family=binomial)
# Left off standard errors on this one
plot(gam2)
```

`gam` also works for logistic regression and other kinds of generalized Linear Models




FIN.



