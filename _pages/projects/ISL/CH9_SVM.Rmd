---
title: "ISL_CH9_SVM"
output: html_document
---

# Linear SVM Classifier

```{r}
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
```
```{r}
library(e1071)
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
print(svmfit)

```
```{r}
plot(svmfit,dat)

```



```{r}
make.grid=function(x,n=75){
  grange=apply(x,2,range)
  x1=seq(from=grange[1,1],to=grange[2,1],length=n)
  x2=seq(from=grange[1,2],to=grange[2,2],length=n)
  expand.grid(X1=x1,X2=x2)
  }
xgrid=make.grid(x)
ygrid=predict(svmfit,xgrid)
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)

```





```{r}
beta=drop(t(svmfit$coefs)%*%x[svmfit$index,])
beta0=svmfit$rho
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
abline(beta0/beta[2],-beta[1]/beta[2])
abline((beta0-1)/beta[2],-beta[1]/beta[2],lty=2)
abline((beta0+1)/beta[2],-beta[1]/beta[2],lty=2)
```
# Nonlinear SVM

```{r}
load(url("http://www.stanford.edu/~hastie/ElemStatLearn/datasets/ESL.mixture.rda"))
names(ESL.mixture)

```

```{r}
rm(x,y)
attach(ESL.mixture)
plot(x,col=y+1)

```
```{r}
dat=data.frame(y=factor(y),x)
fit=svm(factor(y)~.,data=dat,scale=FALSE,kernel="radial",cost=5)
```

```{r}
xgrid=expand.grid(X1=px1,X2=px2)
ygrid=predict(fit,xgrid)
plot(xgrid,col=as.numeric(ygrid),pch=20,cex=.2)
points(x,col=y+1,pch=19)

```
```{r}
func=predict(fit,xgrid,decision.values=TRUE)
func=attributes(func)$decision
xgrid=expand.grid(X1=px1,X2=px2)
ygrid=predict(fit,xgrid)
plot(xgrid,col=as.numeric(ygrid),pch=20,cex=.2)
points(x,col=y+1,pch=19)

contour(px1,px2,matrix(func,69,99),level=0,add=TRUE)
contour(px1,px2,matrix(prob,69,99),level=.5,add=TRUE,col="blue",lwd=2)
```
## PLAYING ON MY OWN

1. Generate random data
2. Classify data with SVM
3. See how well it classified and get test error
```{r}
library(MASS)
set.seed(315)
X0 <- MASS::mvrnorm(n=10, mu=c(1,1,1,1,1,0,0,0,0,0), Sigma=diag(10))
plot(X0)


```


```{r}
set.seed(10111)
# MAKE 20 OBSERVATIONS in TWO classes on TWO variables
x=matrix(rnorm(40),20,2)
# MAKE A Y VARIABLE (either -1 or 1),
# 10 in each class
y=rep(c(-1,1),c(10,10))
# We are moving the means from 0 to 1 (WHY!?)
x[y==1,]=x[y==1,]+1
# COL = COLOR
plot(x,col=y+6,pch=19)
```
```{r}
set.seed(10111)
# MAKE 20 OBSERVATIONS in TWO classes on TWO variables
x=matrix(rnorm(40),20,2)
# MAKE A Y VARIABLE (either -1 or 1),
# 10 in each class
y=rep(c(-1,1),c(10,10))
# We are moving the means from 0 to 1 (WHY!?)
x[y==1,]=x[y==1,]+3
# COL = COLOR
plot(x,col=y+6,pch=19)
```



```{r}
library(e1071)
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
print(svmfit)
summary(svmfit)
```
```{r}
set.seed(10111)
# MAKE 20 OBSERVATIONS in TWO classes on TWO variables
x=matrix(rnorm(100),50,2)
# MAKE A Y VARIABLE (either -1 or 1),
# 10 in each class
y=rep(c(-1,1),c(25,25))
# We are moving the means from 0 to 1 (WHY!?)
x[y==1,]=x[y==1,]+3
# COL = COLOR
plot(x,col=y+6,pch=19)

```

```{r}
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
print(svmfit)
summary(svmfit)
```
```{r}
set.seed(1)
tune.out=tune(svm ,y~.,data=dat ,kernel ="radial", 
              ranges =list(cost=c(0.001,0.01,0.1, 1,5,10,100)))
summary(tune.out)
```


FIN. 