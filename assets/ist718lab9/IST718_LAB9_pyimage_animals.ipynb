{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IST718_LAB9_pyimage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH08wd2sFCaS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# STEP 1: Import ALL the things!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzMBuqNjFLpW",
        "colab_type": "text"
      },
      "source": [
        "### The packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHqH2_vWSAiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19036295-f983-4ae9-df14-0de3b53ee503"
      },
      "source": [
        "DATASET = 'animals'\n",
        "TEST_IMAGE = 'images/panda.jpg'\n",
        "\n",
        "# DATASET = 'jcrew'\n",
        "# TEST_IMAGE = 'images/jc_test.jpeg'"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.18 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu4-ERnHNmsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "aa67d333-9081-4ffe-cb69-1b5610dd0a5f"
      },
      "source": [
        "# !pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 3.45 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhxjztVAEzCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "899a7763-6339-4cf0-f535-981a877fd8f1"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import SGD\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 9.22 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xChZPBFMFNzU",
        "colab_type": "text"
      },
      "source": [
        "### The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwQuv_fJFTYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "86843590-0398-478c-d08e-97506ec074c8"
      },
      "source": [
        "## mount your Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "time: 2.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRb3TFWLFZAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d5e6ac7-a0c7-42b3-ca4b-d74420a8a95f"
      },
      "source": [
        "## change into the directory where your data is \n",
        "## **** ONLY NEED TO DO THIS ONCE PER RUNTIME ****\n",
        "\n",
        "# os.chdir(\"drive/My Drive/data\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 851 Âµs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWoW6Hz-LH3e",
        "colab_type": "text"
      },
      "source": [
        "# STEP 2: Process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSeTQROULK21",
        "colab_type": "text"
      },
      "source": [
        "1. Get image paths. Shuffle them.\n",
        "2. Loop over the paths and and load the images\n",
        "\n",
        "Inside the loop (for each image)\n",
        "\n",
        "* resize the image\n",
        "* flatten the image\n",
        "* store the (newly flattened & resized) image in 'data' array\n",
        "* store the label in 'labels' array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rhoOyRLFtfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "da1548a7-ab8f-429b-ed14-661075c6b598"
      },
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# imagePaths = sorted(list(paths.list_images('animals')))\n",
        "imagePaths = sorted(list(paths.list_images(DATASET)))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.resize(image, (32, 32)).flatten()\n",
        "\tdata.append(image)\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n",
            "time: 18.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uXx6ylGFw94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ad0dd36-57ab-4424-9910-826b18a90d10"
      },
      "source": [
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 55.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgrNfIZF4DQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fcea144-884c-4f49-d2f4-52f1d7da5dd0"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "\tlabels, test_size=0.25, random_state=42)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 32.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f1LlWpKMMrv",
        "colab_type": "text"
      },
      "source": [
        "## Convert the labels from integers to vectors \n",
        "\n",
        "NOTE: for 2-class, binary classification you should use Keras' to_categorical function instead as the scikit-learn's LabelBinarizer will not return a\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdfDNXltF4xU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37798041-6c60-4876-a4ef-a6638ee928df"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 7.36 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCPr5-TOMk13",
        "colab_type": "text"
      },
      "source": [
        "# STEP 3: MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnSjL-I0F6aQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91eca174-6cc8-42f6-e71c-927b6ea082e4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
        "model.add(Dense(512, activation=\"sigmoid\"))\n",
        "model.add(Dense(len(lb.classes_), activation=\"softmax\"))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 45.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUQtkZu3Mop1",
        "colab_type": "text"
      },
      "source": [
        "1. Initialize learning rate and # of epochs\n",
        "2. Compile the model using:\n",
        "\n",
        "* OPTIMIZER: SGD\n",
        "* LOSS: categorical cross-entropy loss\n",
        "\n",
        "NOTE: use binary_crossentropy for 2-class classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoz2LYdfF7_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05bb3aaa-5d2d-4aa3-ef74-b1b289b99a91"
      },
      "source": [
        "INIT_LR = 0.01\n",
        "EPOCHS = 75\n",
        "\n",
        "print(\"[INFO] training network...\")\n",
        "opt = SGD(lr=INIT_LR)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "time: 45.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNjPPiCoNCwx",
        "colab_type": "text"
      },
      "source": [
        "# STEP 4: Train the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jit8j3crF-uJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2929e2f3-6d3c-4811-f14c-a4b8a272de19"
      },
      "source": [
        "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "\tepochs=EPOCHS, batch_size=32)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2263 samples, validate on 755 samples\n",
            "Epoch 1/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 1.0965 - acc: 0.3880 - val_loss: 1.0748 - val_acc: 0.4768\n",
            "Epoch 2/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 1.0789 - acc: 0.4034 - val_loss: 1.0870 - val_acc: 0.3298\n",
            "Epoch 3/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 1.0552 - acc: 0.4547 - val_loss: 1.0589 - val_acc: 0.4013\n",
            "Epoch 4/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 1.0383 - acc: 0.4560 - val_loss: 1.0419 - val_acc: 0.4808\n",
            "Epoch 5/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 1.0173 - acc: 0.4954 - val_loss: 1.0222 - val_acc: 0.4927\n",
            "Epoch 6/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9992 - acc: 0.5179 - val_loss: 1.0165 - val_acc: 0.4530\n",
            "Epoch 7/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9865 - acc: 0.5055 - val_loss: 0.9918 - val_acc: 0.5258\n",
            "Epoch 8/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9674 - acc: 0.5263 - val_loss: 1.0201 - val_acc: 0.4848\n",
            "Epoch 9/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9568 - acc: 0.5157 - val_loss: 0.9978 - val_acc: 0.4980\n",
            "Epoch 10/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9436 - acc: 0.5219 - val_loss: 0.9683 - val_acc: 0.4980\n",
            "Epoch 11/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9302 - acc: 0.5356 - val_loss: 0.9511 - val_acc: 0.5285\n",
            "Epoch 12/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9187 - acc: 0.5422 - val_loss: 0.9657 - val_acc: 0.4861\n",
            "Epoch 13/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.9054 - acc: 0.5493 - val_loss: 0.9547 - val_acc: 0.4940\n",
            "Epoch 14/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8979 - acc: 0.5409 - val_loss: 0.9436 - val_acc: 0.4887\n",
            "Epoch 15/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8901 - acc: 0.5506 - val_loss: 0.9311 - val_acc: 0.5152\n",
            "Epoch 16/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8824 - acc: 0.5404 - val_loss: 0.9232 - val_acc: 0.5298\n",
            "Epoch 17/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8759 - acc: 0.5479 - val_loss: 0.9150 - val_acc: 0.5656\n",
            "Epoch 18/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8692 - acc: 0.5586 - val_loss: 0.9191 - val_acc: 0.5470\n",
            "Epoch 19/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8638 - acc: 0.5546 - val_loss: 0.9147 - val_acc: 0.5311\n",
            "Epoch 20/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8600 - acc: 0.5683 - val_loss: 0.9464 - val_acc: 0.5205\n",
            "Epoch 21/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8530 - acc: 0.5811 - val_loss: 0.9095 - val_acc: 0.5338\n",
            "Epoch 22/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8509 - acc: 0.5625 - val_loss: 0.9044 - val_acc: 0.5656\n",
            "Epoch 23/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8439 - acc: 0.5802 - val_loss: 0.9030 - val_acc: 0.5166\n",
            "Epoch 24/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8438 - acc: 0.5656 - val_loss: 0.8902 - val_acc: 0.5629\n",
            "Epoch 25/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8411 - acc: 0.5669 - val_loss: 0.8925 - val_acc: 0.5311\n",
            "Epoch 26/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8384 - acc: 0.5700 - val_loss: 0.8885 - val_acc: 0.5430\n",
            "Epoch 27/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8343 - acc: 0.5643 - val_loss: 0.8836 - val_acc: 0.5589\n",
            "Epoch 28/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8313 - acc: 0.5762 - val_loss: 0.9028 - val_acc: 0.5139\n",
            "Epoch 29/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8298 - acc: 0.5714 - val_loss: 0.8873 - val_acc: 0.5510\n",
            "Epoch 30/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8261 - acc: 0.5700 - val_loss: 0.9187 - val_acc: 0.5325\n",
            "Epoch 31/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8222 - acc: 0.5873 - val_loss: 0.8812 - val_acc: 0.5642\n",
            "Epoch 32/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8210 - acc: 0.5771 - val_loss: 0.8823 - val_acc: 0.5510\n",
            "Epoch 33/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8204 - acc: 0.5890 - val_loss: 0.8753 - val_acc: 0.5576\n",
            "Epoch 34/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8164 - acc: 0.5793 - val_loss: 0.8955 - val_acc: 0.5338\n",
            "Epoch 35/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8148 - acc: 0.5851 - val_loss: 0.8790 - val_acc: 0.5510\n",
            "Epoch 36/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8154 - acc: 0.5815 - val_loss: 0.8803 - val_acc: 0.5298\n",
            "Epoch 37/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8139 - acc: 0.5806 - val_loss: 0.8731 - val_acc: 0.5656\n",
            "Epoch 38/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8127 - acc: 0.5758 - val_loss: 0.8894 - val_acc: 0.5404\n",
            "Epoch 39/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8074 - acc: 0.5846 - val_loss: 0.8696 - val_acc: 0.5722\n",
            "Epoch 40/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8069 - acc: 0.5829 - val_loss: 0.8753 - val_acc: 0.5616\n",
            "Epoch 41/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8032 - acc: 0.5829 - val_loss: 0.8709 - val_acc: 0.5497\n",
            "Epoch 42/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7993 - acc: 0.6085 - val_loss: 0.8828 - val_acc: 0.5815\n",
            "Epoch 43/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8053 - acc: 0.5939 - val_loss: 0.8757 - val_acc: 0.5642\n",
            "Epoch 44/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.8049 - acc: 0.5855 - val_loss: 0.8632 - val_acc: 0.5748\n",
            "Epoch 45/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7998 - acc: 0.6027 - val_loss: 0.8823 - val_acc: 0.5576\n",
            "Epoch 46/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7997 - acc: 0.6001 - val_loss: 0.8808 - val_acc: 0.5510\n",
            "Epoch 47/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7973 - acc: 0.5890 - val_loss: 0.8812 - val_acc: 0.5298\n",
            "Epoch 48/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7970 - acc: 0.5908 - val_loss: 0.8711 - val_acc: 0.5642\n",
            "Epoch 49/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7962 - acc: 0.5921 - val_loss: 0.8733 - val_acc: 0.5709\n",
            "Epoch 50/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7956 - acc: 0.5943 - val_loss: 0.8601 - val_acc: 0.5748\n",
            "Epoch 51/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7914 - acc: 0.5948 - val_loss: 0.8761 - val_acc: 0.5589\n",
            "Epoch 52/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7906 - acc: 0.5992 - val_loss: 0.8773 - val_acc: 0.5510\n",
            "Epoch 53/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7886 - acc: 0.6058 - val_loss: 0.8664 - val_acc: 0.5828\n",
            "Epoch 54/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7857 - acc: 0.6014 - val_loss: 0.8627 - val_acc: 0.5775\n",
            "Epoch 55/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7867 - acc: 0.6032 - val_loss: 0.8625 - val_acc: 0.5735\n",
            "Epoch 56/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7830 - acc: 0.6067 - val_loss: 0.8591 - val_acc: 0.5629\n",
            "Epoch 57/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7826 - acc: 0.6063 - val_loss: 0.8763 - val_acc: 0.5417\n",
            "Epoch 58/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7818 - acc: 0.6036 - val_loss: 0.8584 - val_acc: 0.5629\n",
            "Epoch 59/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7816 - acc: 0.6014 - val_loss: 0.8783 - val_acc: 0.5391\n",
            "Epoch 60/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7812 - acc: 0.6120 - val_loss: 0.8834 - val_acc: 0.5483\n",
            "Epoch 61/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7795 - acc: 0.6041 - val_loss: 0.8585 - val_acc: 0.5775\n",
            "Epoch 62/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7753 - acc: 0.6072 - val_loss: 0.8568 - val_acc: 0.5868\n",
            "Epoch 63/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7775 - acc: 0.6036 - val_loss: 0.8582 - val_acc: 0.5669\n",
            "Epoch 64/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7727 - acc: 0.6209 - val_loss: 0.8536 - val_acc: 0.5828\n",
            "Epoch 65/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7705 - acc: 0.6116 - val_loss: 0.8916 - val_acc: 0.5550\n",
            "Epoch 66/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7707 - acc: 0.6182 - val_loss: 0.8563 - val_acc: 0.5907\n",
            "Epoch 67/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7719 - acc: 0.6186 - val_loss: 0.8570 - val_acc: 0.5775\n",
            "Epoch 68/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7706 - acc: 0.6186 - val_loss: 0.8863 - val_acc: 0.5417\n",
            "Epoch 69/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7663 - acc: 0.6240 - val_loss: 0.8635 - val_acc: 0.5722\n",
            "Epoch 70/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7685 - acc: 0.6098 - val_loss: 0.8580 - val_acc: 0.5921\n",
            "Epoch 71/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7655 - acc: 0.6195 - val_loss: 0.8543 - val_acc: 0.5868\n",
            "Epoch 72/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7648 - acc: 0.6138 - val_loss: 0.8965 - val_acc: 0.5351\n",
            "Epoch 73/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7612 - acc: 0.6213 - val_loss: 0.8767 - val_acc: 0.5510\n",
            "Epoch 74/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7616 - acc: 0.6244 - val_loss: 0.8944 - val_acc: 0.5483\n",
            "Epoch 75/75\n",
            "2263/2263 [==============================] - 3s 1ms/step - loss: 0.7594 - acc: 0.6222 - val_loss: 0.8740 - val_acc: 0.5523\n",
            "time: 3min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05o03GCaNMJC",
        "colab_type": "text"
      },
      "source": [
        "# STEP 5: Evaluate the trained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhhRpgtGAdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "520b564f-1dc1-45fa-df48-42dd8f676ac2"
      },
      "source": [
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
        "\n",
        "N = np.arange(0, EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig('results.png')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.47      0.75      0.58       249\n",
            "        dogs       0.48      0.23      0.31       257\n",
            "       panda       0.74      0.68      0.71       249\n",
            "\n",
            "    accuracy                           0.55       755\n",
            "   macro avg       0.56      0.56      0.53       755\n",
            "weighted avg       0.56      0.55      0.53       755\n",
            "\n",
            "time: 411 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFfOLWUHO23E",
        "colab_type": "text"
      },
      "source": [
        "# STEP 6: Test the model on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJzVn0GjGDbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0792729-c12f-40c5-9ee1-bc7741e319b8"
      },
      "source": [
        "image = cv2.imread(TEST_IMAGE)\n",
        "output = image.copy()\n",
        "\n",
        "## doing the same pre-processing we did above\n",
        "image = cv2.resize(image, (32, 32))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = image.flatten()\n",
        "image = image.reshape((1, image.shape[0]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 265 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Nv1JmwQn61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "dd4bd465-0ab5-4389-dd05-904da5fb68da"
      },
      "source": [
        "preds = model.predict(image)\n",
        "\n",
        "## take the label with the highest probability\n",
        "i = preds.argmax(axis=1)[0]\n",
        "label = lb.classes_[i]\n",
        "print(label, preds[0][i])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "panda 0.99365956\n",
            "time: 7.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa2fgYGEQv54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}