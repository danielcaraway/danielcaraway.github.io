{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, you can use not only the word features, but also some other calculated features like sentence length, average word length, whether negations occur, or anything you can define and calculate.\n",
    "\n",
    "sklearn provides a featureUnion tool to combine features from difference sources.\n",
    "http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html#sphx-glr-auto-examples-hetero-feature-union-py\n",
    "\n",
    "This feature union tool uses pipeline. It is powerful tool, but it is not convenient for storing and checking intermediate results. Below is a slower but more intuitive approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at a simple example that adds a feature to detect negations in text. Here negation is simply defined as the occurrence of any of the three words: \"not\", \"no\", and \"never\". In this example a pandas dataframe is created to store the original text data in one column and the generated negation feature in another column. Later the text data will be vectorized, and pandas.sparse.hstack() will be used to combine the vectors and the negation feature together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               text  neg\n",
      "0      this is good    0\n",
      "1       this is bad    0\n",
      "2  this is not good    1\n",
      "3   this is not bad    1\n",
      "4   this is useless    0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "txts = ['this is good', 'this is bad', 'this is not good', 'this is not bad', 'this is useless']\n",
    "df = pd.DataFrame({'text':txts})\n",
    "pattern_neg = re.compile(r'\\b(not|no|never)\\b')\n",
    "df['neg'] = df['text'].apply(lambda x: 1 if pattern_neg.search(x.lower()) else 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or you can define a more complicated function separately for negation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               text  neg\n",
      "0      this is good    0\n",
      "1       this is bad    0\n",
      "2  this is not good    1\n",
      "3   this is not bad    1\n",
      "4   this is useless    1\n"
     ]
    }
   ],
   "source": [
    "def has_negation(post):\n",
    "    pattern_neg_1 = re.compile(r'\\b(not|no|never)\\b')\n",
    "    pattern_neg_2 = re.compile(r'\\b([a-z]+less)\\b')\n",
    "    if pattern_neg_1.search(post.lower()) or pattern_neg_2.search(post.lower()):\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "df['neg'] = df['text'].apply(lambda x: 1 if has_negation(x) else 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now vectorize the text and combine the word vectors with the negation feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (3, 5)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "unigram_bool = CountVectorizer(encoding='latin-1', binary=True)\n",
    "vecs = unigram_bool.fit_transform(df['text']).astype(float)\n",
    "#print(vecs)\n",
    "X_dense = df[['neg']]\n",
    "X_sparse = vecs\n",
    "X = sparse.hstack([X_sparse, X_dense]).tocsr()\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try this approach on the Kaggle sentiment data, and see how much improvement can simple negation detection offer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/byu/Desktop/data/kaggle/train.tsv\", delimiter='\\t')\n",
    "y=train['Sentiment']\n",
    "\n",
    "pattern_neg = re.compile(r'\\b(not|no|never)\\b')\n",
    "train['neg'] = train['Phrase'].apply(lambda x: 1 if pattern_neg.search(x.lower()) else 0)\n",
    "X_dense = train[['neg']]\n",
    "X_sparse = unigram_bool.fit_transform(train['Phrase']).astype(float)\n",
    "X = sparse.hstack([X_sparse, X_dense]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569293741676\n",
      "CPU times: user 265 ms, sys: 77.4 ms, total: 342 ms\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the model with negation detection\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "svm_clf= LinearSVC()\n",
    "scores = cross_val_score(svm_clf, X, y, cv=3, n_jobs=3)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output:\n",
    "    \n",
    "0.569293741676\n",
    "CPU times: user 265 ms, sys: 77.4 ms, total: 342 ms\n",
    "Wall time: 1min 37s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569223263356\n",
      "CPU times: user 263 ms, sys: 74.1 ms, total: 337 ms\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test the model without negation detection\n",
    "# note this cross validation is not the standard pipeline method\n",
    "# but a cut-corner version that does vectorization first and then train/test models\n",
    "# this cut-corner version would allow the model to see the text of the test data, \n",
    "# but the model would still not see the labels of the test data\n",
    "svm_clf2= LinearSVC()\n",
    "scores2 = cross_val_score(svm_clf2, X_sparse, y, cv=3, n_jobs=3)\n",
    "avg2=sum(scores2)/len(scores2)\n",
    "print(avg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output:\n",
    "\n",
    "0.569223263356\n",
    "CPU times: user 263 ms, sys: 74.1 ms, total: 337 ms\n",
    "Wall time: 1min 43s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 15241)\n",
      "10.998846619193118\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "num_more_correct_predictions = X.shape[0]*(0.569293741676 - 0.569223263356)\n",
    "num_more_correct_predictions = 156060*(0.569293741676 - 0.569223263356)\n",
    "print(num_more_correct_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 11 more correct predictions with added negation detection, considering this negation detector is rather simplistic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
